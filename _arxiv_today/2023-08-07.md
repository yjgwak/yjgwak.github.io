---
title: Mon, 7 Aug 2023
date: 2023-08-07
---
1. 9.8 [Deep Policy Gradient Methods in Commodity Markets](https://arxiv.org/abs/2308.01910)
* Authors: Jonas Hanetho
* This paper has the potential to be highly influential as it discusses deep reinforcement learning for commodities trading - a problem of high practical significance. The paper demonstrates significant improvement over traditional methods and may have a considerable impact on the area of algorithmic trading.

2. 9.7 [Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods](https://arxiv.org/abs/2308.01938)
* Authors: Gabriel R. Lencione, Fernando J. Von Zuben
* This work tackles the problem of multi-task learning in a novel way, the proposed solution is scalable and relevant for real-world applications.

3. 9.5 [Accurate Neural Network Pruning Requires Rethinking Sparse Optimization](https://arxiv.org/abs/2308.02060)
* Authors: Denis Kuznedelev, Eldar Kurtic, Eugenia Iofinova, Elias Frantar, Alexandra Peste, Dan Alistarh
* This paper addresses the important question of model pruning in deep learning and sheds light on the relationship between sparsity and optimization, which are key issues underlying many contemporary machine learning algorithms.

4. 9.3 [Learning Optimal Admission Control in Partially Observable Queueing Networks](https://arxiv.org/abs/2308.02391)
* Authors: Jonatha Anselmi, Bruno Gaujal, Louis-SÃ©bastien Rebuffi
* The methods proposed in this paper can be influential for any application domain that relies on queueing theory, from computer networks, telecommunications, production lines, and service organizations, etc.

5. 9.0 [Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives](https://arxiv.org/abs/2308.02066)
* Authors: Chuntao Ding, Zhichao Lu, Shangguang Wang, Ran Cheng, Vishnu Naresh Boddeti
* This paper proposes a novel approach for multi-task learning and could influence future machine learning designs and applications. The authors present a new technique for managing task interference, which is a common challenge in deep learning models trained on multiple tasks.

