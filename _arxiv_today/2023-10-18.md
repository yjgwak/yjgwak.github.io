---
title: Wed, 18 Oct 2023
date: 2023-10-18
---
1. 9.4 [Non-ergodicity in reinforcement learning: robustness via ergodicity transformations](https://arxiv.org/abs/2310.11335)
* Authors: Dominik Baumann, Erfaun Noorani, James Price, Ole Peters, Colm Connaughton, Thomas B. Schön
* Reason: This paper discusses a significant challenge in real-world RL applications by focusing on the optimization objective. It suggests implementing ergodicity transformations to learning robust policies, an innovative approach that might have high impact on the RL domain.

2. 9.2 [Robust Multi-Agent Reinforcement Learning via Adversarial Regularization: Theoretical Foundation and Stable Algorithms](https://arxiv.org/abs/2310.10810)
* Authors: Alexander Bukharin, Yan Li, Yue Yu, Qingru Zhang, Zhehui Chen, Simiao Zuo, Chao Zhang, Songan Zhang, Tuo Zhao
* Reasons: This paper provides a substantial contribution to Robust Multi-Agent Reinforcement Learning. The new MARL framework ERNIE, which promotes the Lipschitz continuity of the policies, is potentially influential in the development of robust MARL algorithms.

3. 9.2 [Charitable Donation and Wealth at Death in Probate Records: Evidence from Ontario, 1892 and 1902](https://arxiv.org/abs/2310.11451)
* Authors: Ming Zhong, Chenxin An, Weizhu Chen, Jiawei Han, Pengcheng He
* Reason: This work evaluates the transferability of knowledge between smaller and larger language models, which is relevant in the context of machine learning and, more specifically, NLP. Its results contribute significantly to understanding the manipulation of LLMs.

4. 9.1 [Reaching the Limit in Autonomous Racing: Optimal Control versus Reinforcement Learning](https://arxiv.org/abs/2310.10943)
* Authors: Yunlong Song, Angel Romero, Matthias Mueller, Vladlen Koltun, Davide Scaramuzza
* Reason: Groundbreaking research where reinforcement learning has outperformed optimal control methods in autonomous drone racing, offering insights into the advantages of RL over OC in robot control.

5. 9.1 [Keep Various Trajectories: Promoting Exploration of Ensemble Policies in Continuous Control](https://arxiv.org/abs/2310.11138)
* Authors: Chao Li, Chen Gong, Qiang He, Xinwen Hou
* Reason: This paper introduces a new ensemble RL algorithm to maximize the expected reward and promote more diverse trajectories, contributing to the real-world applications of RL.

6. 9.0 [A Modified EXP3 and Its Adaptive Variant in Adversarial Bandits with Multi-User Delayed Feedback](https://arxiv.org/abs/2310.11188)
* Authors: Yandi Li, Jianxiong Guo
* Reason: The researchers address the adversarial multi-armed bandit problem with delayed feedback. By designing a modified EXP3 algorithm, they provide valid solutions to one of the challenges in machine learning, contributing significantly to the advancement of the domain.

7. 8.9 [Uncertainty-aware transfer across tasks using hybrid model-based successor feature reinforcement learning](https://arxiv.org/abs/2310.10818)
* Authors: Parvin Malekzadeh, Ming Hou, Konstantinos N. Plataniotis
* Reasons: This paper introduces a novel hybrid model-based successor feature algorithm which has potential to significantly enhance performance across tasks with different transition dynamics. The work is highly relevant to the field of reinforcement learning and might influence future advancements.

8. 8.8 [Combat Urban Congestion via Collaboration: Heterogeneous GNN-based MARL for Coordinated Platooning and Traffic Signal Control](https://arxiv.org/abs/2310.10948)
* Authors: Xianyue Peng, Hang Gao, Hao Wang, H. Michael Zhang
* Reason: Unique approach using reinforcement learning to tackle real-time traffic congestion, providing a model for future urban traffic management.

9. 8.7 [Dual Cognitive Architecture: Incorporating Biases and Multi-Memory Systems for Lifelong Learning](https://arxiv.org/abs/2310.11341)
* Authors: Shruthi Gowda, Bahram Zonooz, Elahe Arani
* Reason: This study introduces the Dual Cognitive Architecture (DUCA), effectively merging principles from multiple components of human cognition. This conceptual advancement could offer a substantial contribution towards the development of lifelong learning algorithms.

10. 8.6 [Context-Aware Meta-Learning](https://arxiv.org/abs/2310.10971)
* Authors: Christopher Fifty, Dennis Duan, Ronald G. Junkins, Ehsan Amid, Jure Leskovec, Christopher Ré, Sebastian Thrun
* Reason: Promising approach to meta-learning by learning new visual concepts during inference without fine-tuning, potentially setting a new direction in the field of visual learning.

11. 8.5 [Joint Optimization of Traffic Signal Control and Vehicle Routing in Signalized Road Networks using Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2310.10856)
* Authors: Xianyue Peng, Hang Gao, Gengyue Han, Hao Wang, Michael Zhang
* Reasons: The paper's approach to optimizing traffic signal control and vehicle routing using Multi-Agent Deep Reinforcement Learning could be highly influential in the future development and practical application of reinforcement learning in transportation systems.

12. 8.4 [From Identifiable Causal Representations to Controllable Counterfactual Generation: A Survey on Causal Generative Modeling](https://arxiv.org/abs/2310.11011)
* Authors: Aneesh Komanduri, Xintao Wu, Yongkai Wu, Feng Chen
* Reason: In-depth survey on causal generative modeling, providing comprehensive insights into the identified challenges and future directions of the field.

13. 8.2 [HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning](https://arxiv.org/abs/2310.11102)
* Authors: Yulan Hu, Zhirui Yang, Sheng Ouyang, Yong Liu
* Reason: Innovative combination of generative and contrastive learning for heterogeneous graph learning, offering potential improvements in the ability of machine learning models to handle diverse and complex datapoints.

14. 8.1 [Proper Laplacian Representation Learning](https://arxiv.org/abs/2310.10833)
* Authors: Diego Gomez, Michael Bowling, Marlos C. Machado
* Reasons: This paper proposes an optimized method for approximating Laplacian representation, providing insights and solutions that may prove influential in the advancement of reinforcement learning in complex environments.

15. 7.9 [Emergent Mixture-of-Experts: Can Dense Pre-trained Transformers Benefit from Emergent Modular Structures?](https://arxiv.org/abs/2310.10908)
* Authors: Zihan Qiu, Zeyu Huang, Jie Fu
* Reasons: Although not directly on reinforcement learning, the research could benefit the future research directions of reinforcement learning by highlighting the advantages of explicit modular architecture in dense pre-trained transformers.

