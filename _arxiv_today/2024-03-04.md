---
title: Mon, 4 Mar 2024
date: 2024-03-04
---
1. 9.0 [Efficient Reinforcement Learning for Global Decision Making in the Presence of Local Agents at Scale](https://arxiv.org/abs/2403.00222)
* Authors: Emile Anand, Guannan Qu
* Reason: Addresses a critical scalability challenge in RL with practical applications, presents novel algorithm with promising results, longer paper suggesting depth of research.

2. 8.9 [EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data](https://arxiv.org/abs/2403.00564)
* Authors: Shengjie Wang, Shaohuai Liu, Weirui Ye, Jiacheng You, Yang Gao
* Reason: The authors extend EfficientZero to diverse domains with significant improvement over state-of-the-art, indicating a groundbreaking approach to sample efficiency which is a key challenge in RL applications.

3. 8.7 [Causal Bandits with General Causal Models and Interventions](https://arxiv.org/abs/2403.00233)
* Authors: Zirui Yan, Dennis Wei, Dmitriy Katz-Rogozhnikov, Prasanna Sattigeri, Ali Tajer
* Reason: Expands the theoretical understanding of CBs with applications to RL, includes generalizations not previously covered, and provides both upper and lower bounds on regret.

4. 8.7 [Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey](https://arxiv.org/abs/2403.00420)
* Authors: Lucas Schott, Josephine Delas, Hatem Hajri, Elies Gherbi, Reda Yaich, Nora Boulahia-Cuppens, Frederic Cuppens, Sylvain Lamprier
* Reason: In-depth exploration and categorization of adversarial attacks to improve DRL robustness is critical for real-world applications, and the authors provide a comprehensive analysis which could shape future research on RL agent resilience.

5. 8.5 [Robust Policy Learning via Offline Skill Diffusion](https://arxiv.org/abs/2403.00225)
* Authors: Woo Kyung Kim, Minjong Yoo, Honguk Woo
* Reason: Proposes an innovative offline skill learning framework and demonstrates its robustness in policy learning across different domains, which is key for transferring skills in RL.

6. 8.5 [Safe Hybrid-Action Reinforcement Learning-Based Decision and Control for Discretionary Lane Change](https://arxiv.org/abs/2403.00446)
* Authors: Ruichen Xu, Xiao Liu, Jinming Xu, Yuan Lin
* Reason: The paper introduces a novel algorithm promoting safety in autonomous driving, a high-impact application area, with demonstrated superiority over previous methods in safety-critical simulations.

7. 8.3 [Robustifying a Policy in Multi-Agent RL with Diverse Cooperative Behavior and Adversarial Style Sampling for Assistive Tasks](https://arxiv.org/abs/2403.00344)
* Authors: Tayuki Osa, Tatsuya Harada
* Reason: Addressing the real-world applicability of multi-agent RL in healthcare for assistive tasks and the proposed solutions for policy robustification could significantly influence the development of RL in cooperative, real-life settings.

8. 8.2 [Go Beyond Black-box Policies: Rethinking the Design of Learning Agent for Interpretable and Verifiable HVAC Control](https://arxiv.org/abs/2403.00172)
* Authors: Zhiyu An, Xianzhong Ding, Wan Du
* Reason: Focuses on improving interpretability and reliability of RL in HVAC control, indicating a step towards practical deployment, backed by significant energy efficiencies proven in experiments.

9. 8.1 [Snapshot Reinforcement Learning: Leveraging Prior Trajectories for Efficiency](https://arxiv.org/abs/2403.00673)
* Authors: Yanxiao Zhao, Yangge Qian, Tianyi Wang, Jingyang Shan, Xiaolin Qin
* Reason: Introduces a framework for improving sample efficiency without modifying existing DRL algorithms, with strong potential for practical adoption due to its flexibility and demonstrated improvement over standard baselines in sample efficiency and average return.

10. 7.9 [Influencing Bandits: Arm Selection for Preference Shaping](https://arxiv.org/abs/2403.00036)
* Authors: Viraj Nadkarni, D. Manjunath, Sharayu Moharir
* Reason: Addresses a novel aspect of non-stationary bandits with real-world implications in preference shaping, though more niche compared to the broader applicability of the other papers listed.

