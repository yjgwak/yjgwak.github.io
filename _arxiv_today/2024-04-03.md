---
title: Wed, 3 Apr 2024
date: 2024-04-03
---
1. 9.4 [Learning to Solve Job Shop Scheduling under Uncertainty](https://arxiv.org/abs/2404.01308)
* Authors: Guillaume Infantes, Stéphanie Roussel, Pierre Pereira, Antoine Jacquet, Emmanuel Benazera
* Reason: Proposes a novel Deep Reinforcement Learning approach to a classic optimization problem with real-world applications, and claims improvements in generalization and scalability. The integration with Graph Neural Networks indicates a strong methodology, and publication at a conference adds to its credibility.

2. 9.1 [Game-Theoretic Deep Reinforcement Learning to Minimize Carbon Emissions and Energy Costs for AI Inference Workloads in Geo-Distributed Data Centers](https://arxiv.org/abs/2404.01459)
* Authors: Ninad Hogade, Sudeep Pasricha
* Reason: Addresses the pressing issue of sustainability in data centers with a novel combination of Game Theory and Deep Reinforcement Learning, which could have significant implications for the industry. The work extends beyond theoretical significance by providing comparative empirical results.

3. 8.8 [TS-CausalNN: Learning Temporal Causal Relations from Non-linear Non-stationary Time Series Data](https://arxiv.org/abs/2404.01466)
* Authors: Omar Faruque, Sahara Ali, Xue Zheng, Jianwu Wang
* Reason: Tackles an important problem in time-series analysis with a deep learning approach that could potentially be influential across various application domains. The proposed neural network architecture is novel and addresses a gap in causal discovery methods for non-stationary and non-linear data.

4. 8.7 [Multi-Agent Reinforcement Learning with Control-Theoretic Safety Guarantees for Dynamic Network Bridging](https://arxiv.org/abs/2404.01551)
* Authors: Raffaele Galliera, Konstantinos Mitsopoulos, Niranjan Suri, Raffaele Romagnoli
* Reason: Introduces a novel integration of MARL with control-theory methods, addresses safety in safety-critical environments, and has experimental results demonstrating the advantages over conventional methods.

5. 8.6 [QuAD: Query-based Interpretable Neural Motion Planning for Autonomous Driving](https://arxiv.org/abs/2404.01486)
* Authors: Sourav Biswas, Sergio Casas, Quinlan Sykora, Ben Agro, Abbas Sadat, Raquel Urtasun
* Reason: Introduces an innovative approach to autonomy in self-driving vehicles through a query-based planning system that could lead to more efficient and interpretable motion planning. With the participation of Raquel Urtasun, who has authority in the field, this work could potentially impact future research in autonomous driving.

6. 8.5 [Addressing Heterogeneity in Federated Load Forecasting with Personalization Layers](https://arxiv.org/abs/2404.01517)
* Authors: Shourya Bose, Yu Zhang, Kibaek Kim
* Reason: Deals with an essential challenge in federated learning and offers an approach that balances local adaptation and global consistency. The practical importance of load forecasting for energy grids and the consideration of privacy concerns could make this paper highly relevant to future development in smart grid management.

7. 8.5 [Distributed Autonomous Swarm Formation for Dynamic Network Bridging](https://arxiv.org/abs/2404.01557)
* Authors: Raffaele Galliera, Thies Möhlenhof, Alessandro Amato, Daniel Duran, Kristen Brent Venable, Niranjan Suri
* Reason: Proposes a MARL approach for a complex problem, uses innovative techniques such as DGN, and includes simulated and near real-world evaluations.

8. 8.3 [Active Exploration in Bayesian Model-based Reinforcement Learning for Robot Manipulation](https://arxiv.org/abs/2404.01867)
* Authors: Carlos Plou, Ana C. Murillo, Ruben Martinez-Cantin
* Reason: Enhances model-based RL with active exploration and Bayesian neural networks, highly relevant for cost-effective robotics, and validates the approach in realistic robot manipulation scenarios.

9. 8.1 [Extremum-Seeking Action Selection for Accelerating Policy Optimization](https://arxiv.org/abs/2404.01598)
* Authors: Ya-Chien Chang, Sicun Gao
* Reason: Introduces a new method to improve model-free RL action selection using Extremum-Seeking Control, applicable to robotic control with complex dynamics, and shows improved efficiency in control learning environments.

10. 7.9 [Learning to Control Camera Exposure via Reinforcement Learning](https://arxiv.org/abs/2404.01636)
* Authors: Kyunghyun Lee, Ukcheol Shin, Byeong-Uk Lee
* Reason: Addresses real-time camera exposure control using deep RL, proposes a novel framework with real-world application relevance, and demonstrates improvements in computer vision tasks.

