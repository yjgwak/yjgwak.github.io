---
title: Mon, 13 Nov 2023
date: 2023-11-13
---
1. 9.3 [Towards Instance-Optimality in Online PAC Reinforcement Learning](https://arxiv.org/abs/2311.05638)
* Authors: Aymen Al-Marjani, Andrea Tirinzoni, Emilie Kaufmann
* Reason: Proposes the first instance-dependent lower bound on the sample complexity for PAC-identification of near-optimal policy in tabular episodic MDPs and hints at a potential breakthrough in computationally-efficient algorithms for reinforcement learning, authored by established researchers.

2. 9.1 [Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs](https://arxiv.org/abs/2311.05657)
* Authors: Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, Bill Yuchen Lin
* Reason: Introduces Lumos, an innovative framework based on open-source large language models for language agents, displaying superior performance and generalization in various task domains and is authored by researchers with substantial contributions in the field.

3. 8.9 [ADaPT: As-Needed Decomposition and Planning with Language Models](https://arxiv.org/abs/2311.05772)
* Authors: Archiki Prasad, Alexander Koller, Mareike Hartmann, Peter Clark, Ashish Sabharwal, Mohit Bansal, Tushar Khot
* Reason: Demonstrates a significant improvement in complex task performance using a novel approach that adapts to LLM capabilities; written by authors who are known for pushing the boundaries in this area of AI and language models.

4. 8.7 [Real-time Control of Electric Autonomous Mobility-on-Demand Systems via Graph Reinforcement Learning](https://arxiv.org/abs/2311.05780)
* Authors: Aaryan Singhal, Daniele Gammelli, Justin Luke, Karthik Gopalakrishnan, Dominik Helmreich, Marco Pavone
* Reason: Addresses a critical real-world application of reinforcement learning for E-AMoD fleet management showing practical and substantial benefits and involves authors with expertise in systems and robotics.

5. 8.5 [Clipped-Objective Policy Gradients for Pessimistic Policy Optimization](https://arxiv.org/abs/2311.05846)
* Authors: Jared Markowitz, Edward W. Staley
* Reason: Presents a novel and simple modification to the PPO objective that enhances learning performance in continuous action spaces, created by authors contributing to practical advancements in reinforcement learning.

