---
title: Fri, 10 Nov 2023
date: 2023-11-10
---
1. 9.2 [Accelerating Exploration with Unlabeled Prior Data](https://arxiv.org/abs/2311.05067)
* Authors: Qiyang Li, Jason Zhang, Dibya Ghosh, Amy Zhang, Sergey Levine
* Reason: The paper addresses the significant challenge of sparse reward signals in reinforcement learning with innovative and practical solutions, authored by experts including Sergey Levine, a highly influential figure in RL.

2. 8.9 [Signal Temporal Logic-Guided Apprenticeship Learning](https://arxiv.org/abs/2311.05084)
* Authors: Aniruddh G. Puranic, Jyotirmoy V. Deshmukh, Stefanos Nikolaidis
* Reason: The paper tackles the complex issue of temporal dependencies in apprenticeship learning with a potential for wide impact on robotics and policy learning methods.

3. 8.6 [Counter-Empirical Attacking based on Adversarial Reinforcement Learning for Time-Relevant Scoring System](https://arxiv.org/abs/2311.05144)
* Authors: Xiangguo Sun, Hong Cheng, Hang Dong, Bo Qiao, Si Qin, Qingwei Lin
* Reason: This work proposes an original framework for improving scoring systems through "counter-empirical attacking," making it relevant for platforms using such systems, including financial services.

4. 8.4 [Anytime-Constrained Reinforcement Learning](https://arxiv.org/abs/2311.05511)
* Authors: Jeremy McMahan, Xiaojin Zhu
* Reason: Anytime constraints are a new addition to constrained MDPs, which could be foundational, and the authors provide planning and learning algorithms that indicate the potential for practical applications.

5. 7.9 [When Meta-Learning Meets Online and Continual Learning: A Survey](https://arxiv.org/abs/2311.05241)
* Authors: Jaehyeon Son, Soochan Lee, Gunhee Kim
* Reason: Although a survey paper, it provides comprehensive coverage of significant learning paradigms that have potential cross-applications and combinations in reinforcement learning.

