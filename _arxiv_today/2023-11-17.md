---
title: Fri, 17 Nov 2023
date: 2023-11-17
---
1. 9.2 [Augmenting Unsupervised Reinforcement Learning with Self-Reference](https://arxiv.org/abs/2311.09692)
* Authors: Andrew Zhao, Erle Zhu, Rui Lu, Matthieu Lin, Yong-Jin Liu, Gao Huang
* Reason: Novel approach for unsupervised reinforcement learning with demonstrated state-of-the-art results and significant impact on both performance and sample efficiency, authored by researchers from prominent institutions.

2. 8.9 [Scalable Diffusion for Materials Generation](https://arxiv.org/abs/2311.09235)
* Authors: Mengjiao Yang, KwangHwan Cho, Amil Merchant, Pieter Abbeel, Dale Schuurmans, Igor Mordatch, Ekin Dogus Cubuk
* Reason: The inclusion of high-profile authors like Pieter Abbeel, and the interdisciplinary nature of the paper (leveraging reinforcement learning for material science) indicate a significant potential for influence across multiple fields of research.

3. 8.7 [Neural Packing: from Visual Sensing to Reinforcement Learning](https://arxiv.org/abs/2311.09233)
* Authors: Juzhan Xu, Minglun Gong, Hao Zhang, Hui Huang, Ruizhen Hu
* Reason: The paper presents a novel RL framework for a real-world combinatorial optimization problem, which includes experimentation with physical robots, indicating a high potential for impact in the robotics and RL communities.

4. 8.7 [Safety Aware Autonomous Path Planning Using Model Predictive Reinforcement Learning for Inland Waterways](https://arxiv.org/abs/2311.09878)
* Authors: Astrid Vanneste, Simon Vanneste, Olivier Vasseur, Robin Janssens, Mattias Billast, Ali Anwar, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx
* Reason: Introduces a novel path planning approach based on reinforcement learning, addressing critical safety concerns in autonomous shipping in urban waterways, with comparisons to existing baselines.

5. 8.4 [Investigating the Impact of Weight Sharing Decisions on Knowledge Transfer in Continual Learning](https://arxiv.org/abs/2311.09506)
* Authors: Josh Andle, Ali Payani, Salimeh Yasaei-Sekeh
* Reason: Addresses an important problem in continual learning within the context of reinforcement learning, providing insights that could significantly influence the development of more efficient knowledge transfer methods.

6. 8.4 [Guaranteeing Control Requirements via Reward Shaping in Reinforcement Learning](https://arxiv.org/abs/2311.10026)
* Authors: Francesco De Lellis, Marco Coraggio, Giovanni Russo, Mirco Musolesi, Mario di Bernardo
* Reason: Proposes a framework for ensuring that reinforcement learning policies meet predetermined control requirements with applications validated in various control problems.

7. 8.2 [Know Thy Neighbors: A Graph Based Approach for Effective Sensor-Based Human Activity Recognition in Smart Homes](https://arxiv.org/abs/2311.09514)
* Authors: Srivatsa P, Thomas Pl√∂tz
* Reason: Proposes a novel approach for activity recognition that can advance smart home technologies, which is a burgeoning application area for reinforcement learning and other ML techniques.

8. 8.0 [SegMix: A Simple Structure-Aware Data Augmentation Method](https://arxiv.org/abs/2311.09505)
* Authors: Yuxin Pei, Pushkar Bhuse, Zhengzhong Liu, Eric Xing
* Reason: While not directly related to reinforcement learning, the application of this method may indirectly influence reinforcement learning research by improving data augmentation techniques for NLP, which often go hand in hand with RL for complex tasks.

9. 8.0 [JaxMARL: Multi-Agent RL Environments in JAX](https://arxiv.org/abs/2311.10090)
* Authors: Alexander Rutherford, Benjamin Ellis, Matteo Gallici, Jonathan Cook, Andrei Lupu, Gardar Ingvarsson, Timon Willi, Akbir Khan, Christian Schroeder de Witt, Alexandra Souly, Saptarashmi Bandyopadhyay, Mikayel Samvelyan, Minqi Jiang, Robert Tjarko Lange, Shimon Whiteson, Bruno Lacerda, Nick Hawes, Tim Rocktaschel, Chris Lu, Jakob Nicolaus Foerster
* Reason: Offers a comprehensive open-source code base with GPU support, likely to enhance multi-agent RL research efficiency and influence methodology in the field due to its performance gains and prominent authoring team.

10. 7.8 [Runtime Verification of Learning Properties for Reinforcement Learning Algorithms](https://arxiv.org/abs/2311.09811)
* Authors: Tommaso Mannucci, Julio de Oliveira Filho
* Reason: Develops new verification techniques for assessing the quality and timeliness of learning in RL algorithms, with potential impact on the reliability and efficiency of RL applications.

