---
title: Mon, 3 Jul 2023
date: 2023-07-03
---
1. 9.5 [Landmark Guided Active Exploration with Stable Low-level Policy Learning](https://arxiv.org/abs/2306.17484)
* Authors: Fei Cui, Jiaojiao Fang, Mengke Yang, Guizhong Liu
* Reason: Novel approach for efficient training and exploration in the domain of Goal-conditioned hierarchical reinforcement learning making active utilization of goal-conditioned value function, with promising experimental results. Considering the citation records of these authors, this paper has a lot of potential to influence the field of reinforcement learning.

2. 9.1 [$λ$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces](https://arxiv.org/abs/2306.17366)
* Authors: Claas A Voelcker, Arash Ahmadian, Romina Abachi, Igor Gilitschenski, Amir-massoud Farahmand
* Reason: The paper gives theoretical backing to decision-aware reinforcement learning models and proposes a valuable framework for continuous state-spaces which can have extensive applications. The authors also pose significant reputation in the field.

3. 8.7 [Probabilistic Constraint for Safety-Critical Reinforcement Learning](https://arxiv.org/abs/2306.17279)
* Authors: Weiqin Chen, Dharmashankar Subramanian, Santiago Paternain
* Reason: This paper tackles the crucial aspect of safety in reinforcement learning, providing several theoretical contributions apart from a novel approach that could change the way we achieve safety in RL applications.

4. 8.4 [Learning Environment Models with Continuous Stochastic Dynamics](https://arxiv.org/abs/2306.17204)
* Authors: Martin Tappler, Edi Muškardin, Bernhard K. Aichernig, Bettina Könighofer
* Reason: The paper presents a scalable approach to learning complex environments helping to enhance control tasks functionality using deep reinforcement learning. The proposed method has shown commendable results on popular benchmarking environments.

5. 8.0 [Optimal Execution Using Reinforcement Learning](https://arxiv.org/abs/2306.17178)
* Authors: Cong Zheng, Jiafa He, Can Yang
* Reason: The paper works on the optimal order execution problem with respect to cryptocurrency exchanges showing promising results but due to the less comprehensive nature and limited scope, it gets a lower score.

