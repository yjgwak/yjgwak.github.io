---
title: Mon, 6 Nov 2023
date: 2023-11-06
---
1. 9.2 [Anytime-Competitive Reinforcement Learning with Policy Prior](https://arxiv.org/abs/2311.01568)
* Authors: Jianyi Yang, Pengfei Li, Tongxin Li, Adam Wierman, Shaolei Ren
* Reason: Accepted at NeurIPS 2023, the paper addresses an important problem - Anytime-Competitive Markov Decision Process (A-CMDP) - and proposes Anytime-Competitive Reinforcement Learning (ACRL) which shows solid experimental results.

2. 8.8 [RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization](https://arxiv.org/abs/2311.01753)
* Authors: Siqi Shen, Chennan Ma, Chao Li, Weiquan Liu, Yongquan Fu, Songzhu Mei, Xinwang Liu, Cheng Wang
* Reason: NeurIPS 2023 submission, presents a novel method - RiskQ - that models the joint return distribution and showcases promising performance via extensive experiments.

3. 8.5 [Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula](https://arxiv.org/abs/2311.01642)
* Authors: Aryaman Reddi, Maximilian TÃ¶lle, Jan Peters, Georgia Chalvatzaki, Carlo D'Eramo
* Reason: Under review, proposes an innovative approach for adversarial RL based on entropy regularization to solve complex saddle point optimization problems, shows strong experimental performance against several benchmarks.

4. 8.3 [Score Models for Offline Goal-Conditioned Reinforcement Learning](https://arxiv.org/abs/2311.02013)
* Authors: Harshit Sikchi, Rohan Chitnis, Ahmed Touati, Alborz Geramifard, Amy Zhang, Scott Niekum
* Reason: Preprint, proposes SMORe - a novel, principled approach to Offline GCRL, capable of leveraging suboptimal offline data, outperforms state-of-the-art baselines in several experimental benchmarks.

5. 8.1 [Optimistic Multi-Agent Policy Gradient for Cooperative Tasks](https://arxiv.org/abs/2311.01953)
* Authors: Wenshuai Zhao, Yi Zhao, Zhiyuan Li, Juho Kannala, Joni Pajarinen
* Reason: Comprehensive 16-pages paper, addresses an essential problem - Relative overgeneralization (RO) - in cooperative multi-agent learning tasks, introduces a novel framework that shows extensive positive results on diverse sets of tasks, including complex Multi-agent MuJoCo and Overcooked benchmarks.

