---
title: Wed, 24 Jan 2024
date: 2024-01-24
---
1. 8.9 [Large-scale Reinforcement Learning for Diffusion Models](https://arxiv.org/abs/2401.12244)
* Authors: Yinan Zhang, Eric Tzeng, Yilun Du, Dmitry Kislyuk
* Reason: The paper addresses a significant challenge in improving the alignment of diffusion models with human preferences and value systems, which is critically important for ethical AI development. The scale at which improvements were demonstrated is expansive and affects a broad user base, indicating a high potential influence in the field of generative models and RL.

2. 8.9 [Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control](https://arxiv.org/abs/2401.12624)
* Authors: Yongjun Kim, Sejin Seo, Jihong Park, Mehdi Bennis, Seong-Lyun Kim, Junil Choi
* Reason: Introduces a novel framework bridging the gap between high training cost emergent communication and the inference cost of semantic computation with pre-trained models; potential applicability in multi-agent systems can impact various disciplines.

3. 8.7 [Stochastic Dynamic Power Dispatch with High Generalization and Few-Shot Adaption via Contextual Meta Graph Reinforcement Learning](https://arxiv.org/abs/2401.12235)
* Authors: Bairong Deng, Tao Yu, Zhenning Pan, Xuehan Zhang, Yufeng Wu, Qiaoyi Ding
* Reason: Tackling real-time optimization in power dispatch with a novel Meta Reinforcement Learning framework addresses both scalability and generalization which are key challenges in applying RL to real-world problems, thus making it influential for energy systems and, more broadly, industrial applications of RL.

4. 8.7 [Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach](https://arxiv.org/abs/2401.12686)
* Authors: Christian Fabian, Kai Cui, Heinz Koeppl
* Reason: Accepted at ICLR 2024 with innovative approach to learning in sparse graph environments which are common in real-world networks, presenting both theoretical and practical advancements in MARL and MFG systems.

5. 8.5 [Constraint-Generation Policy Optimization (CGPO): Nonlinear Programming for Policy Optimization in Mixed Discrete-Continuous MDPs](https://arxiv.org/abs/2401.12243)
* Authors: Michael Gimelfarb, Ayal Taitler, Scott Sanner
* Reason: Introducing a novel framework for policy optimization using mixed-integer nonlinear optimization is a potentially game-changing approach for a variety of fields where both discrete and continuous actions are required, marking high technical novelty and interdisciplinary influence.

6. 8.5 [Dynamic Layer Tying for Parameter-Efficient Transformers](https://arxiv.org/abs/2401.12819)
* Authors: Tamir David Hay, Lior Wolf
* Reason: Targets efficiency in deep transformer models through an innovative application of reinforcement learning, potentially reducing resource consumption and driving future research in parameter-efficient model training.

7. 8.3 [Emergent Dominance Hierarchies in Reinforcement Learning Agents](https://arxiv.org/abs/2401.12258)
* Authors: Ram Rachum, Yonatan Nakar, Bill Tomlinson, Nitay Alon, Reuth Mirsky
* Reason: The exploration of social conventions like dominance hierarchies within the context of multi-agent systems can have substantial implications for the development of cooperative behaviors in AI, making it a noteworthy contribution to studies of emergent behaviors and social dynamics in RL.

8. 8.2 [Learning safety critics via a non-contractive binary bellman operator](https://arxiv.org/abs/2401.12849)
* Authors: Agustin Castellano, Hancheng Min, Juan Andr√©s Bazerque, Enrique Mallada
* Reason: Addresses critical safety challenges in RL with novel theoretical contributions, potentially influencing applications where safety is paramount, such as autonomous systems and robotics.

9. 8.1 [Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation](https://arxiv.org/abs/2401.12275)
* Authors: Jiachen Li, Chuanbo Hua, Hengbo Ma, Jinkyoo Park, Victoria Dax, Mykel J. Kochenderfer
* Reason: Enhancing social robot navigation through advanced relational reasoning showcases significant benefits in multi-agent interactions and could influence both the research and development of autonomous systems interacting in social spaces such as robots for assistance and delivery services.

10. 8.0 [Reward-Relevance-Filtered Linear Offline Reinforcement Learning](https://arxiv.org/abs/2401.12934)
* Authors: Angela Zhou
* Reason: Provides new methods and theoretical insights for offline RL with linear function approximation focusing on sparsity in the decision-making process, promising to improve policy learning where data acquisition is expensive or risky.

