---
title: Thu, 14 Sep 2023
date: 2023-09-14
---
1. 9.9 [A Q-learning Approach for Adherence-Aware Recommendations](https://arxiv.org/abs/2309.06519)
* Authors: Ioannis Faros, Aditya Dave, Andreas A. Malikopoulos
* Reason: Direct application of reinforcement learning with real-world impact in scenarios involving high-stakes decisions.

2. 9.5 [Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning](https://arxiv.org/abs/2309.06553)
* Authors: Hao Sun
* Reason: Application of Inverse-RL to a novel problem of prompt optimization.

3. 9.3 [Reasoning with Latent Diffusion in Offline Reinforcement Learning](https://arxiv.org/abs/2309.06599)
* Authors: Siddarth Venkatraman, Shivesh Khaitan, Ravi Tej Akella, John Dolan, Jeff Schneider, Glen Berseth
* Reason: Focuses on major problem in offline RL of effectively stitching suboptimal trajectories.

4. 9.1 [Attention Loss Adjusted Prioritized Experience Replay](https://arxiv.org/abs/2309.06684)
* Authors: Zhuoying Chen, Huiping Li, Rizhong Wang
* Reason: Improvement on Prioritized Experience Replay, a pivotal technique in deep reinforcement learning.

5. 9.0 [Safe Reinforcement Learning with Dual Robustness](https://arxiv.org/abs/2309.06835)
* Authors: Zeyang Li, Chuxiong Hu, Yunan Wang, Yujie Yang, Shengbo Eben Li
* Reason: Addressing the crucial yet challenging issue of creating RL agents that are both safe and robust.

