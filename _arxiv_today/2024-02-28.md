---
title: Wed, 28 Feb 2024
date: 2024-02-28
---
1. 8.9 [Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings](https://arxiv.org/abs/2402.17135)
* Authors: Kevin Frans, Seohong Park, Pieter Abbeel, Sergey Levine
* Reason: This paper addresses the challenging problem of zero-shot generalization in reinforcement learning with novel methodology and involvement from high-profile authors like Pieter Abbeel and Sergey Levine, whose past work has proven impactful in the field.

2. 8.9 [Reinforced In-Context Black-Box Optimization](https://arxiv.org/abs/2402.17423)
* Authors: Lei Song, Chenxiao Gao, Ke Xue, Chenyang Wu, Dong Li, Jianye Hao, Zongzhang Zhang, Chao Qian
* Reason: This paper introduces a novel method named RIBBO to reinforce-learn a Black-Box Optimization algorithm which could have broad applications, including robotics and hyper-parameter optimization, indicating a strong potential influence by shifting Black-Box Optimization towards a more flexible, data-driven approach.

3. 8.7 [Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning](https://arxiv.org/abs/2402.17217)
* Authors: Zijian Guo, Weichao Zhou, Wenchao Li
* Reason: The paper introduces an innovative approach to safe reinforcement learning using temporal logic specifications, a promising application in real-world scenarios where safety is a critical concern.

4. 8.7 [Multi-Agent Deep Reinforcement Learning for Distributed Satellite Routing](https://arxiv.org/abs/2402.17666)
* Authors: Federico Lozano-Cuadra, Beatriz Soret
* Reason: Represents a significant advancement in low Earth orbit satellite constellation routing, which is a pivotal area with increased relevance due to the rise of satellite-based communication networks. The MA-DRL approach may set a precedent for future distributed systems.

5. 8.5 [A prior Estimates for Deep Residual Network in Continuous-time Reinforcement Learning](https://arxiv.org/abs/2402.16899)
* Authors: Shuyu Yin, Qixuan Zhou, Fei Wen, Tao Luo
* Reason: Addresses the under-explored area of continuous-time control problems in reinforcement learning, potentially opening up new avenues for research and application.

6. 8.5 [Beacon, a lightweight deep reinforcement learning benchmark library for flow control](https://arxiv.org/abs/2402.17402)
* Authors: Jonathan Viquerat, Philippe Meliga, Pablo Jeken, Elie Hachem
* Reason: The authors propose Beacon, an open-source benchmark library for flow control problems in fluid dynamics. The contribution can foster research reproducibility and set benchmarks, potentially accelerating the use of deep RL in this area.

7. 8.3 [Stochastic Gradient Succeeds for Bandits](https://arxiv.org/abs/2402.17235)
* Authors: Jincheng Mei, Zixin Zhong, Bo Dai, Alekh Agarwal, Csaba Szepesvari, Dale Schuurmans
* Reason: Offers significant theoretical advancements in understanding stochastic gradient bandit algorithms, supported by a robust set of experimental results.

8. 8.3 [DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning](https://arxiv.org/abs/2402.17453)
* Authors: Siyuan Guo, Cheng Deng, Ying Wen, Hechang Chen, Yi Chang, Jun Wang
* Reason: This paper presents a novel framework combining large language models with case-based reasoning for automating data science tasks, which could have a considerable impact on the future of automated machine learning systems.

9. 8.1 [RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences](https://arxiv.org/abs/2402.17257)
* Authors: Jie Cheng, Gang Xiong, Xingyuan Dai, Qinghai Miao, Yisheng Lv, Fei-Yue Wang
* Reason: Tackles the problem of robustness in preference-based RL and can have a substantial impact on real-world applications sensitive to human feedback noise.

10. 8.1 [Label-Noise Robust Diffusion Models](https://arxiv.org/abs/2402.17517)
* Authors: Byeonghu Na, Yeongmin Kim, HeeSun Bae, Jung Hyun Lee, Se Jung Kwon, Wanmo Kang, Il-Chul Moon
* Reason: Addresses the challenging problem of learning with noisy labels for conditional diffusion models, an area that is gaining importance for generative tasks across a wide range of datasets. The methodology could impart a strong influence on improving the fidelity and robustness of generative models.

