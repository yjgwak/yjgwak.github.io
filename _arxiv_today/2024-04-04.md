---
title: Thu, 4 Apr 2024
date: 2024-04-04
---
1. 8.6 [Deep Reinforcement Learning for Traveling Purchaser Problems](https://arxiv.org/abs/2404.02476)
* Authors: Haofeng Yuan, Rongping Zhu, Wanlu Yang, Shiji Song, Keyou You, Yuli Zhang
* Reason: Introduces a novel DRL approach to a complex optimization problem with significant performance improvements demonstrated through rigorous benchmarking and possesses potential for broad application.

2. 8.4 [Is Exploration All You Need? Effective Exploration Characteristics for Transfer in Reinforcement Learning](https://arxiv.org/abs/2404.02235)
* Authors: Jonathan C. Balloch, Rishav Bhagat, Geigh Zollicoffer, Ruoran Jia, Julia Kim, Mark O. Riedl
* Reason: Addresses a fundamental challenge in deep RL pertaining to exploration strategies, showcasing a thorough analysis that is likely to influence future research on transfer learning in RL.

3. 8.2 [Decision Transformer as a Foundation Model for Partially Observable Continuous Control](https://arxiv.org/abs/2404.02407)
* Authors: Xiangyuan Zhang, Weichao Mao, Haoran Qiu, Tamer Ba≈üar
* Reason: Explores a transformer-based architecture for control tasks demonstrating potential as a foundational model for a variety of applications, with compelling zero-shot generalization results.

4. 8.0 [Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning](https://arxiv.org/abs/2404.02545)
* Authors: Yi Shen, Hanyan Huang, Shan Xie
* Reason: Presents a count-based strategy for dealing with out-of-distribution actions in offline RL, a critical issue in the field, with promising results on benchmark datasets.

5. 7.8 [AD4RL: Autonomous Driving Benchmarks for Offline Reinforcement Learning with Value-based Dataset](https://arxiv.org/abs/2404.02429)
* Authors: Dongsu Lee, Chanin Eom, Minhae Kwon
* Reason: Provides much-needed benchmarks and datasets for autonomous driving, facilitating the practical application and evaluation of offline RL algorithms in real-world scenarios.

