---
title: Mon, 18 Dec 2023
date: 2023-12-18
---
1. 8.9 [iOn-Profiler: intelligent Online multi-objective VNF Profiling with Reinforcement Learning](https://arxiv.org/abs/2312.09355)
* Authors: Xenofon Vasilakos, Shadi Moazzeni, Anderson Bravalheri, Pratchaya Jaisudthi, Reza Nejabati, Dimitra Simeonidou
* Reason: The paper introduces a novel RL application in optimizing virtual network functions (VNFs), proposing a multi-objective resource allocation model that demonstrates clear improvements in performance and efficiency. The paper's potential influence is increased given the detailed experimental evaluation with real-world VNF types and a substantial list of authors, some of whom may be authorities in their field.

2. 8.5 [Temporal Transfer Learning for Traffic Optimization with Coarse-grained Advisory Autonomy](https://arxiv.org/abs/2312.09436)
* Authors: Jung-Hoon Cho, Sirui Li, Jeongyun Kim, Cathy Wu
* Reason: Addresses an innovative application of reinforcement learning for optimizing urban traffic with connected and automated vehicles (CAVs). The introduction of Temporal Transfer Learning (TTL) for a range of advisory tasks and its validation in diverse traffic scenarios makes this paper stand out. The potential impact of this research is high given the growing interest in smart cities and traffic optimization.

3. 8.4 [Optimal Regret Bounds for Collaborative Learning in Bandits](https://arxiv.org/abs/2312.09674)
* Authors: Amitis Shidani, Sattar Vakili
* Reason: Authors address a novel problem with practical implications and achieve order optimal regret bounds, indicating a significant advance in multi-agent reinforcement learning.

4. 8.2 [GraphRARE: Reinforcement Learning Enhanced Graph Neural Network with Relative Entropy](https://arxiv.org/abs/2312.09708)
* Authors: Tianhao Peng, Wenjun Wu, Haitao Yuan, Zhifeng Bao, Zhao Pengrui, Xin Yu, Xuetao Lin, Yu Liang, Yanjun Pu
* Reason: The paper tackles an important limitation in GNNs with a novel approach, which could have substantial impact on node classification tasks in reinforcement learning applications.

5. 8.1 [A Hierarchical Nearest Neighbour Approach to Contextual Bandits](https://arxiv.org/abs/2312.09332)
* Authors: Stephen Pasteris, Chris Hicks, Vasilios Mavroudis
* Reason: This paper approaches the adversarial contextual bandit problem with an algorithm that has high computational efficiency and improved regret terms. It may have significant influence in fields where decision-making under uncertainty and adversarial conditions is critical.

6. 7.9 [Small Dataset, Big Gains: Enhancing Reinforcement Learning by Offline Pre-Training with Model Based Augmentation](https://arxiv.org/abs/2312.09844)
* Authors: Girolamo Macaluso, Alessandro Sestini, Andrew D. Bagdanov
* Reason: Introduces a creative approach to improve offline reinforcement learning, demonstrating potential for substantial influence in settings with limited data availability.

7. 7.8 [Enhancing Trajectory Prediction through Self-Supervised Waypoint Noise Prediction](https://arxiv.org/abs/2312.09466)
* Authors: Pranav Singh Chib, Pravendra Singh
* Reason: The paper proposes a novel self-supervised learning method (SSWNP) for improving trajectory predictions, which can have significant implications for autonomous navigation and related fields. It is potentially influential but depends on the validation and adoption of its proposed method in practical applications.

8. 7.7 [Assume-Guarantee Reinforcement Learning](https://arxiv.org/abs/2312.09938)
* Authors: Milad Kazemi, Mateo Perez, Fabio Somenzi, Sadegh Soudjani, Ashutosh Trivedi, Alvaro Velasquez
* Reason: Presents a modular approach to RL which could make learning in complex environments more feasible, suggesting a promising direction for scalability improvements.

9. 7.5 [Safe Reinforcement Learning in a Simulated Robotic Arm](https://arxiv.org/abs/2312.09468)
* Authors: Luka Kovač, Igor Farkaš
* Reason: Presents an extension of safe reinforcement learning for a Panda robotic arm environment, a domain that is clearly pertinent to the applicability of reinforcement learning in physical and interactive scenarios. Could be influential in promoting safety in RL applications, but as an initial study, its impact is still uncertain.

10. 7.5 [Peer Learning: Learning Complex Policies in Groups from Scratch via Action Recommendations](https://arxiv.org/abs/2312.09950)
* Authors: Cedric Derstroff, Mattia Cerrato, Jannis Brugger, Jan Peters, Stefan Kramer
* Reason: Proposes an innovative learning framework for group agent reinforcement learning. While newer, this framework is promising for studying complex policy evolutions and could become increasingly influential.

