---
title: Wed, 20 Dec 2023
date: 2023-12-20
---
1. 9.2 [Robust Communicative Multi-Agent Reinforcement Learning with Active Defense](https://arxiv.org/abs/2312.11545)
* Authors: Lebin Yu, Yunbo Qiu, Quanming Yao, Yuan Shen, Xudong Zhang, Jian Wang
* Reason: Accepted by AAAI 2024, and the focus on communication robustness in MARL is a critical aspect of real-world applications.

2. 9.2 [Emergence of In-Context Reinforcement Learning from Noise Distillation](https://arxiv.org/abs/2312.12275)
* Authors: Ilya Zisman, Vladislav Kurenkov, Alexander Nikulin, Viacheslav Sinii, Sergey Kolesnikov
* Reason: Introduces a novel approach in the emergent field of in-context reinforcement learning, potentially addressing the challenge of multi-task learning with suboptimal demonstrators through noise distillation.

3. 9.0 [Prediction and Control in Continual Reinforcement Learning](https://arxiv.org/abs/2312.11669)
* Authors: Nishanth Anand, Doina Precup
* Reason: Published at NeurIPS 2023, which is a highly prestigious conference, and addresses the important aspect of continual learning in RL.

4. 9.0 [Value Explicit Pretraining for Goal-Based Transfer Learning](https://arxiv.org/abs/2312.12339)
* Authors: Kiran Lekkala, Henghui Bao, Sumedh Sontakke, Laurent Itti
* Reason: Proposes an innovative pretraining method aimed at facilitating the transfer of learning across tasks in reinforcement learning, with potential application across various RL problems.

5. 8.9 [On the Effectiveness of Retrieval, Alignment, and Replay in Manipulation](https://arxiv.org/abs/2312.12345)
* Authors: Norman Di Palo, Edward Johns
* Reason: Offers insights into imitation learning efficiency improvement, with a focus on visual observations critical for reinforcement learning in robotics.

6. 8.7 [Curriculum Learning for Cooperation in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2312.11768)
* Authors: Rupali Bhati, Sai Krishna Gottipati, Clod√©ric Mars, Matthew E. Taylor
* Reason: Presented at NeurIPS 2023, focuses on cooperation in MARL, an area of growing interest and applicability.

7. 8.7 [Chasing Fairness in Graphs: A GNN Architecture Perspective](https://arxiv.org/abs/2312.12369)
* Authors: Zhimeng Jiang, Xiaotian Han, Chao Fan, Zirui Liu, Na Zou, Ali Mostafavi, Xia Hu
* Reason: Addresses fairness in machine learning with a specific focus on graph neural networks, which is a timely issue and may spur further research into ethical AI.

8. 8.5 [Neural Network Approximation for Pessimistic Offline Reinforcement Learning](https://arxiv.org/abs/2312.11863)
* Authors: Di Wu, Yuling Jiao, Li Shen, Haizhao Yang, Xiliang Lu
* Reason: Accepted to AAAI 2024, offers theoretical insights into offline RL with practical implications for deep learning models.

9. 8.5 [Device Scheduling for Relay-assisted Over-the-Air Aggregation in Federated Learning](https://arxiv.org/abs/2312.12417)
* Authors: Fan Zhang, Jining Chen, Kunlun Wang, Wen Chen
* Reason: Tackles the efficient device scheduling problem in federated learning, which has implications for the scale and efficiency of RL algorithms in distributed environments.

10. 8.3 [Optimistic Policy Gradient in Multi-Player Markov Games with a Single Controller: Convergence Beyond the Minty Property](https://arxiv.org/abs/2312.12067)
* Authors: Ioannis Anagnostides, Ioannis Panageas, Gabriele Farina, Tuomas Sandholm
* Reason: To appear at AAAI 2024, provides a new framework for optimistic policy gradient methods, relevant for both theory and application in multi-player games.

