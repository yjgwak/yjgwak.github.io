---
title: Thu, 7 Dec 2023
date: 2023-12-07
---
1. 9.5 [MACCA: Offline Multi-agent Reinforcement Learning with Causal Credit Assignment](https://arxiv.org/abs/2312.03644)
* Authors: Ziyan Wang, Yali Du, Yudi Zhang, Meng Fang, Biwei Huang
* Reason: Authors offer a promising approach to credit assignment in offline MARL, a foundational aspect of efficient multi-agent systems, with solid theoretical backing, indicating a high potential for influence in developing robust multi-agent RL systems.

2. 9.3 [SDSRA: A Skill-Driven Skill-Recombination Algorithm for Efficient Policy Learning](https://arxiv.org/abs/2312.03216)
* Authors: Eric H. Jiang, Andrew Lizarraga
* Reason: Presentation of a novel RL algorithm that enhances efficiency, with reported superior performance over existing techniques. The innovative combination with skill-based strategies suggests a strong impact on multiple complex tasks within RL.

3. 8.9 [Generalized Contrastive Divergence: Joint Training of Energy-Based Model and Diffusion Model through Inverse Reinforcement Learning](https://arxiv.org/abs/2312.03397)
* Authors: Sangwoong Yoon, Dohyun Kwon, Himchan Hwang, Yung-Kyun Noh, Frank C. Park
* Reason: The paper introduces a novel objective function for simultaneous EBM and sampler training, presenting a unique perspective that aligns with inverse RL, with potential implications for enhancing sample quality and training efficiency.

4. 8.7 [Diffused Task-Agnostic Milestone Planner](https://arxiv.org/abs/2312.03395)
* Authors: Mineui Hong, Minjae Kang, Songhwai Oh
* Reason: The proposed method addresses long-term planning and multi-task decision-making using diffusion models, showing superior results in benchmarks which could significantly influence the field of long-horizon, sparse-reward tasks and planning.

5. 8.6 [I-PHYRE: Interactive Physical Reasoning](https://arxiv.org/abs/2312.03009)
* Authors: Shiqian Li, Kewen Wu, Chi Zhang, Yixin Zhu
* Reason: This work extends the realm of physical reasoning in RL to dynamic scenes and introduces a new framework, thereby highlighting a gap in current capabilities and the necessity of further research, indicating possible influence on future interactive RL systems.

