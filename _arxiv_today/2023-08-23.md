---
title: Wed, 23 Aug 2023
date: 2023-08-23
---
1. 9.9 [Automated mapping of virtual environments with visual predictive coding](https://arxiv.org/abs/2308.10913)
* Authors: James Gornet, Matthew Thomson
* Reason: The paper presents a unified algorithmic framework for constructing spatial maps using sensory data, based on predictive coding. It has the potential to extend to various input types like auditory and linguistic, hence promising a broader impact.

2. 9.5 [SPEGTI: Structured Prediction for Efficient Generative Text-to-Image Models](https://arxiv.org/abs/2308.10997)
* Authors: Sadeep Jayasumana, Daniel Glasner, Srikumar Ramalingam, Andreas Veit, Ayan Chakrabarti, Sanjiv Kumar
* Reason: The authors propose a light-weight approach for text-to-image generation which has significant computational advances over previous methods. This paper has a significant impact on improving performance and speed of text-to-image models.

3. 9.5 [ProAgent: Building Proactive Cooperative AI with Large Language Models](https://arxiv.org/abs/2308.11339)
* Authors: Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang, Junge Zhang, Feng Yin, Yitao Liang, Yaodong Yang
* Reason: This paper presents a novel framework for developing cooperative intelligence with the ability to anticipate future decisions and formulate improved plans. The authors demonstrate significant performance improvements over self-play and population-based training methods.

4. 9.3 [Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes](https://arxiv.org/abs/2308.11267)
* Authors: David M. Bossens
* Reason: The paper introduces two significant algorithms, tackling the problem of robustness in reinforcement learning with behavioural constraints and errors in the transition dynamics model. Theoretical analysis and empirical experiments reveal the effectiveness and competitive performance of these algorithms.

5. 9.1 [Efficient Last-iterate Convergence Algorithms in Solving Games](https://arxiv.org/abs/2308.11256)
* Authors: Linjian Meng, Zhenxing Ge, Wenbin Li, Bo An, Yang Gao
* Reason: This paper provides a closer analysis of the reward transformation framework in the context of reinforcement learning. The design of a novel method to improve empirical performance emphasizes the importance and potential influence of this work.

6. 9.0 [Neural Amortized Inference for Nested Multi-agent Reasoning](https://arxiv.org/abs/2308.11071)
* Authors: Kunal Jha, Tuan Anh Le, Chuanyang Jin, Yen-Ling Kuo, Joshua B. Tenenbaum, Tianmin Shu
* Reason: The paper proposes a novel method that accelerates higher-order social inference - a critical component of multi-agent interactions - ensuring computational efficiency without significantly compromising accuracy.

7. 8.9 [FoX: Formation-aware exploration in multi-agent reinforcement learning](https://arxiv.org/abs/2308.11272)
* Authors: Yonghyeon Jo, Sunwoo Lee, Junghyuk Yum, Seungyul Han
* Reason: The paper addresses the scalability issue of the exploration space in multi-agent reinforcement learning. The proposed framework shows significant performance improvement over state-of-the-art multi-agent reinforcement learning algorithms, underlining its potential influence.

8. 8.8 [Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge](https://arxiv.org/abs/2308.10918)
* Authors: Hwan Kim, Junghoon Kim, Byung Suk Lee, Sungsu Lim
* Reason: The authors introduce a new framework for graph anomaly detection, which improves learning differences in structures and attributes on real-world networks, paving the way for improved anomaly detection on attributed networks.

9. 8.7 [Careful at Estimation and Bold at Exploration](https://arxiv.org/abs/2308.11348)
* Authors: Xing Chen, Yijun Liu, Zhaogeng Liu, Hechang Chen, Hengshuai Yao, Yi Chang
* Reason: This paper introduces a novel exploration strategy in continuous action space, with the potential to significantly improve the performance of deterministic policy reinforcement learning. Experimental results demonstrate superior performance compared to state-of-the-art methods.

10. 8.6 [Instance-based Learning with Prototype Reduction for Real-Time Proportional Myocontrol: A Randomized User Study Demonstrating Accuracy-preserving Data Reduction for Prosthetic Embedded Systems](https://arxiv.org/abs/2308.11019)
* Authors: Tim Sziburis, Markus Nowak, Davide Brunelli
* Reason: This work presents learning techniques for gesture detection in prosthetic control, evaluating methods of dataset reduction for efficient real-time prediction. It presents significant developments in the field of prosthetics with practical implications.

