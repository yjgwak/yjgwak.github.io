---
title: Mon, 24 Jul 2023
date: 2023-07-24
---
1. 9.1 [Kernelized Offline Contextual Dueling Bandits](https://arxiv.org/abs/2307.11288)
* Authors: Viraj Mehta, Ojash Neopane, Vikramjeet Das, Sen Lin, Jeff Schneider, Willie Neiswanger
* The paper introduces a unique upper-confidence-bound style algorithm for the offline contextual dueling bandit setting with comprehensive empirical evidence confirming its performance.

2. 8.9 [Model-based Offline Reinforcement Learning with Count-based Conservatism](https://arxiv.org/abs/2307.11352)
* Authors: Byeongchan Kim, Min-hwan Oh
* This paper proposes a fresh perspective on model-based offline RL that integrates count-based conservatism, an unexplored area in model-based offline RL, substantiated by numerical experiments outperforming existing offline RL algorithms.

3. 8.8 [Diverse Offline Imitation via Fenchel Duality](https://arxiv.org/abs/2307.11373)
* Authors: Marin Vlastelica, Pavel Kolev, Jin Cheng, Georg Martius
* This paper presents an innovative offline skill discovery algorithm anchoring Fenchel duality, reinforcement learning, and unsupervised skill discovery to effectively learn an array of tasks aligned with an expert.

4. 8.5 [Towards practical reinforcement learning for tokamak magnetic control](https://arxiv.org/abs/2307.11546)
* Authors: Brendan D. Tracey, Andrea Michi, Yuri Chervonyi, Ian Davies, Cosmin Paduraru, Nevena Lazic, Federico Felici, Timo Ewalds...
* The authors are presenting a novel approach of application of RL in real-time control systems of plasma magnetic control and potentially improving accuracy by up to 65%.

5. 8.4 [Exploring reinforcement learning techniques for discrete and continuous control tasks in the MuJoCo environment](https://arxiv.org/abs/2307.11166)
* Authors: Vaddadi Sai Rahul, Debajyoti Chakraborty
* The paper goes into extensive detail about the application of RL in physics simulations, comparing various techniques and showcasing the outperformance of a specific method, DDPG, over traditional strategies.

