---
title: Fri, 7 Jul 2023
date: 2023-07-07
---
1. 9.5 [Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance](https://arxiv.org/abs/2307.03119)
* Authors: Yuchen Fang, Zhenggang Tang, Kan Ren, Weiqing Liu, Li Zhao, Jiang Bian, Dongsheng Li, Weinan Zhang, Yong Yu, Tie-Yan Liu
* Reason: This paper is influential due to its integration of multi-agent reinforcement learning for multi-order execution in finance, an area of high practical importance. Additionally, its advanced communication protocol for agent interaction demonstrates potential for widespread utility.

2. 9.3 [Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation](https://arxiv.org/abs/2307.02842)
* Authors: Yu Chen, Yihan Du, Pihe Hu, Siwei Wang, Desheng Wu, Longbo Huang
* Reason: This paper addresses the much-needed safety considerations in reinforcement learning by proposing an algorithm for risk-sensitive RL with function approximation. Its novel techniques and mathematical rigor make it highly influential.

3. 9.2 [Offline Reinforcement Learning with Imbalanced Datasets](https://arxiv.org/abs/2307.02752)
* Authors: Li Jiang, Sijie Chen, Jielin Qiu, Haoran Xu, Wai Kin Chan, Zhao Ding
* Reason: This paper brings attention to an important and understudied aspect of RL, i.e., the effect of imbalanced datasets. The paper not only identifies the issues but also proposes a method to address the imbalance, making it impactfully influential.

4. 9.1 [Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill-Learning](https://arxiv.org/abs/2307.02728)
* Authors: Andrew Levy, Sreehari Rammohan, Alessandro Allievi, Scott Niekum, George Konidaris
* Reason: This paper introduces Hierarchical Empowerment, a new framework that effectively deals with the challenge of learning large skill sets. The ability to learn skills to cover a larger surface area as demonstrated makes it significant and potentially influential.

5. 9.0 [Stability of Q-Learning Through Design and Optimism](https://arxiv.org/abs/2307.02632)
* Authors: Sean Meyn
* Reason: This paper dives deep into the fundamental concepts of Q-learning and proposes new approaches to ensure stability in these algorithms. Considering the foundational knowledge it contributes on stability of Q-Learning with linear function approximation, it is set to be a highly influential paper.

